{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "27VpzqkL3uit"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom google.colab import drive\\ndrive.mount('/content/gdrive')\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YRTH4Bx52TTb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "\n",
    "import keras,os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yg7u7UKF26l5"
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [224, 224]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1AG7O3lT2cU6"
   },
   "source": [
    "Now just remember the architecture in mind and start adding the layers into the network. our Kernel_size is (3,3) and the pool_size is (2,2) always."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZaDSUUnX2d9B"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2),name='vgg16'))\n",
    "model.add(Flatten(name='flatten'))\n",
    "model.add(Dense(256, activation='relu', name='fc1'))\n",
    "model.add(Dense(128, activation='relu', name='fc2'))\n",
    "model.add(Dense(1, activation='sigmoid', name='output'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8pqCDVI92_bs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jjs04sdE3IFo"
   },
   "source": [
    "To use a pre-trained model just makes the middle layers non trainable and remove the last layer.\n",
    "\n",
    "We are also going to do the same let’s makes the middle layers freeze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3Wr-qETp3FPZ"
   },
   "outputs": [],
   "source": [
    "for layer in vgg.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AYsUlKJw3LT5"
   },
   "source": [
    "We have already removed the output layer by include_top = False.\n",
    "\n",
    "Let’s add our own output layer with only one node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cAyuCmLh3NSV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 25089     \n",
      "=================================================================\n",
      "Total params: 14,739,777\n",
      "Trainable params: 25,089\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = Flatten()(vgg.output)\n",
    "prediction = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=vgg.input, outputs=prediction)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WWD7PTY3R1G"
   },
   "source": [
    "Now we need to compile our model so that we can train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "EXkL3ZvO3Phd"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  #optimizer='adam',\n",
    "  #optimizer='opt',\n",
    "  optimizer='rmsprop',\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "StMKpa7c3UJw"
   },
   "source": [
    "Let’s generate training and validation data using the data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "zjIFvfV83WJU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2145 images belonging to 5 classes.\n",
      "Found 236 images belonging to 5 classes.\n",
      "Found 250 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path=\"datasets/Buildings224/train\"\n",
    "test_path=\"datasets/Buildings224/test\"\n",
    "\n",
    "#train_path=\"/content/gdrive/My Drive/datasets/Buildings224/train\"\n",
    "#test_path=\"/content/gdrive/My Drive/datasets/Buildings224/test\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                   height_shift_range=0.3, \n",
    "                                   width_shift_range=0.3, \n",
    "                                   channel_shift_range=150.0, \n",
    "                                   brightness_range=(0.3, 0.9),\n",
    "                                   validation_split=0.1) #validation split\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 16,\n",
    "    class_mode='categorical',\n",
    "    subset='training') # set as training data\n",
    "\n",
    "validation_set = train_datagen.flow_from_directory(\n",
    "    train_path, # same directory as training data\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 16,\n",
    "    class_mode='categorical',\n",
    "    subset='validation') # set as validation data\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(test_path,\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 16,\n",
    "                                            class_mode = 'categorical',\n",
    "                                            shuffle=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1U-y7It479j"
   },
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "v4LifZF-3jUU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "135/135 [==============================] - 609s 5s/step - loss: 1.1921e-07 - accuracy: 0.2277 - val_loss: 1.1921e-07 - val_accuracy: 0.2305\n",
      "Epoch 2/11\n",
      "135/135 [==============================] - 760s 6s/step - loss: 1.1921e-07 - accuracy: 0.2260 - val_loss: 1.1921e-07 - val_accuracy: 0.2254\n",
      "Epoch 3/11\n",
      "135/135 [==============================] - 791s 6s/step - loss: 1.1921e-07 - accuracy: 0.2338 - val_loss: 1.1921e-07 - val_accuracy: 0.2305\n",
      "Epoch 4/11\n",
      "135/135 [==============================] - 823s 6s/step - loss: 1.1921e-07 - accuracy: 0.2280 - val_loss: 1.1921e-07 - val_accuracy: 0.2305\n",
      "Epoch 5/11\n",
      "135/135 [==============================] - 767s 6s/step - loss: 1.1921e-07 - accuracy: 0.2269 - val_loss: 1.1921e-07 - val_accuracy: 0.2229\n",
      "Epoch 6/11\n",
      "135/135 [==============================] - 514s 4s/step - loss: 1.1921e-07 - accuracy: 0.2285 - val_loss: 1.1921e-07 - val_accuracy: 0.2280\n",
      "Epoch 7/11\n",
      "135/135 [==============================] - 366s 3s/step - loss: 1.1921e-07 - accuracy: 0.2294 - val_loss: 1.1921e-07 - val_accuracy: 0.2432\n",
      "Epoch 8/11\n",
      "135/135 [==============================] - 372s 3s/step - loss: 1.1921e-07 - accuracy: 0.2274 - val_loss: 1.1921e-07 - val_accuracy: 0.2254\n",
      "Epoch 9/11\n",
      "135/135 [==============================] - 396s 3s/step - loss: 1.1921e-07 - accuracy: 0.2291 - val_loss: 1.1921e-07 - val_accuracy: 0.2331\n",
      "Epoch 10/11\n",
      "135/135 [==============================] - 406s 3s/step - loss: 1.1921e-07 - accuracy: 0.2249 - val_loss: 1.1921e-07 - val_accuracy: 0.2127\n",
      "Epoch 11/11\n",
      "135/135 [==============================] - 379s 3s/step - loss: 1.1921e-07 - accuracy: 0.2257 - val_loss: 1.1921e-07 - val_accuracy: 0.2381\n"
     ]
    }
   ],
   "source": [
    "r = model.fit(\n",
    "  train_set,\n",
    "  #steps_per_epoch = train_set.samples,\n",
    "  validation_data = validation_set, \n",
    "  #validation_steps = validation_set.samples,\n",
    "  epochs = 11,\n",
    "  shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4YDTSH8Q458C"
   },
   "source": [
    "Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "oUPMJIfu44QW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 33s 2s/step - loss: 1.1921e-07 - accuracy: 0.2168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1920928955078125e-07, 0.2168000042438507]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "luaaV9PHVGTk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting... \n",
      "16/16 [==============================] - 27s 2s/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"predicting... \")\n",
    "\n",
    "#Confution Matrix and Classification Report\n",
    "Y_pred = model.predict(test_set, len(test_set), verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[50  0  0  0  0]\n",
      " [50  0  0  0  0]\n",
      " [50  0  0  0  0]\n",
      " [50  0  0  0  0]\n",
      " [50  0  0  0  0]]\n",
      "Classification Report\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Arch_Bridges       0.20      1.00      0.33        50\n",
      "         Castles       0.00      0.00      0.00        50\n",
      "        Churches       0.00      0.00      0.00        50\n",
      "          Towers       0.00      0.00      0.00        50\n",
      "Triumphal_Arches       0.00      0.00      0.00        50\n",
      "\n",
      "        accuracy                           0.20       250\n",
      "       macro avg       0.04      0.20      0.07       250\n",
      "    weighted avg       0.04      0.20      0.07       250\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gecko/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gecko/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gecko/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#print(Y_pred)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "#print(y_pred)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_set.labels, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['Arch_Bridges', 'Castles', 'Churches', 'Towers', 'Triumphal_Arches']\n",
    "print(classification_report(test_set.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "vgg-img-augmentation+validation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
